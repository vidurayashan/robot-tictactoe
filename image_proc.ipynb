{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053579a8-2c70-468a-a346-fd9e1feb43e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "import threading\n",
    "import DobotDllType as dType\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401cb0f-195f-4acb-99c7-fbc78082188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a connection to the default camera (usually the first camera device found)\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    # exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44952d3a-f287-49bb-8dfd-a6d7a5e719e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    while True:\n",
    "        # Read a frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # If frame reading was not successful, break the loop\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert the frame from BGR (OpenCV format) to RGB (Matplotlib format)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Display the frame using Matplotlib\n",
    "        plt.imshow(frame_rgb)\n",
    "        plt.axis('off')  # Hide axis\n",
    "        display(plt.gcf())  # Display the current figure\n",
    "        clear_output(wait=True)  # Clear the output to update the display\n",
    "\n",
    "        # Wait for 1 second before capturing the next frame\n",
    "        time.sleep(1)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "# Release the camera\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61894f0c-c7ec-4646-8d0a-4d54df295af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bec9b6-4a8e-4e4e-88e9-d1f5fa5774e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the main image and the template\n",
    "main_image = cv2.imread('image2-edit.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# ret, frame = cap.read()\n",
    "# main_image = cv2.cvtColor(frame, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0cd79-a89d-44c6-851c-947b3af71920",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(main_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ee666-2602-491e-a531-c5a84eb0202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_image = cv2.imread('star2.PNG', cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(template_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a12d5-b06a-4873-a204-e7e08eb1b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Find keypoints and descriptors with ORB\n",
    "kp1, des1 = orb.detectAndCompute(template_image, None)\n",
    "kp2, des2 = orb.detectAndCompute(main_image, None)\n",
    "\n",
    "# Create a BFMatcher object with default parameters\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "\n",
    "# Match descriptors\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Apply ratio test\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.8 * n.distance:\n",
    "        good_matches.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4a2c52-ef3d-4798-a3d4-91a74668b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match in good_matches:\n",
    "    print(match.distance, match.imgIdx, match.queryIdx, match.trainIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb07f93c-7ace-43bd-a107-4d0b42307f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "des1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584da2a6-2f5b-49fd-be76-1e44582a606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1[0].pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ec5fd0-f6b7-44d8-9a48-840485d91e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c466787c-02e1-47d5-9cb6-63cf702f2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the good matches based on distance\n",
    "good_matches = sorted(good_matches, key=lambda x: x.distance)\n",
    "\n",
    "# Find the best two matches that are at least 30 pixels away from each other\n",
    "best_match_1 = None\n",
    "best_match_2 = None\n",
    "\n",
    "if len(good_matches) >= 2:\n",
    "    best_match_1 = good_matches[0]\n",
    "    pt1 = kp2[best_match_1.trainIdx].pt\n",
    "\n",
    "    for match in good_matches[1:]:\n",
    "        pt2 = kp2[match.trainIdx].pt\n",
    "        if np.linalg.norm(np.array(pt1) - np.array(pt2)) >= 20:\n",
    "            best_match_2 = match\n",
    "            break\n",
    "\n",
    "if best_match_1 and best_match_2:\n",
    "    pt1 = kp2[best_match_1.trainIdx].pt\n",
    "    pt2 = kp2[best_match_2.trainIdx].pt\n",
    "\n",
    "    print(f\"Best match 1 coordinates: {pt1}\")\n",
    "    print(f\"Best match 2 coordinates: {pt2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46854c7-4020-427e-abd6-0907deb3af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kp2[best_match_2.trainIdx].pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3e6938-3fa5-45ae-85a3-620dc62855b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the best two matches\n",
    "img_matches = cv2.drawMatches(template_image, kp1, main_image, kp2, [best_match_1, best_match_2], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# Show matches\n",
    "plt.imshow(img_matches)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f84ba71-be8d-4f88-ac1f-190eb5a44133",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_circles = main_image.copy()\n",
    "cv2.circle(img_with_circles, (int(pt1[0]), int(pt1[1])), 5, (0, 255, 0), -1)\n",
    "cv2.circle(img_with_circles, (int(pt2[0]), int(pt2[1])), 5, (0, 0, 255), -1)\n",
    "\n",
    "# Show the image with circles\n",
    "plt.imshow(img_with_circles, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812b47b0-49ba-493e-89ef-80193c5f390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cord = {}\n",
    "def gen_cord(pt1, pt2):\n",
    "    x1, y1 = pt1[0], pt1[1]\n",
    "    x2, y2 = pt2[0], pt2[1]\n",
    "\n",
    "    middle_x, middle_y = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    size = abs(x1 - x2) / 3\n",
    "\n",
    "    pos_cord[1] = ( middle_x - size, middle_y - size )\n",
    "    pos_cord[2] = ( middle_x,        middle_y - size )\n",
    "    pos_cord[3] = ( middle_x + size, middle_y - size )\n",
    "    pos_cord[4] = ( middle_x - size, middle_y )\n",
    "    pos_cord[5] = ( middle_x,        middle_y )\n",
    "    pos_cord[6] = ( middle_x + size, middle_y )\n",
    "    pos_cord[7] = ( middle_x - size, middle_y + size )\n",
    "    pos_cord[8] = ( middle_x,        middle_y + size)\n",
    "    pos_cord[9] = ( middle_x + size, middle_y + size)\n",
    "\n",
    "def draw_circle(img, x, y):\n",
    "    img_cpy = img.copy()\n",
    "    cv2.circle(img_cpy, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
    "    return img_cpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab81a1e6-5768-4ddb-a22b-7676aecccdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cord(pt1, pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3272cf7-1aa0-426a-b1d6-67e4c41793bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a960f2-38f1-415f-9538-82cda6f81bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,10):\n",
    "    print(idx)\n",
    "    img = draw_circle(img_with_circles, pos_cord[idx][0], pos_cord[idx][1])\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de4eafb-4d6e-43c8-afe8-e35b12eddfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dll and get the CDLL object\n",
    "api = dType.load()\n",
    "#建立与dobot的连接\n",
    "#Connect Dobot\n",
    "state = dType.ConnectDobot(api, \"\", 115200)[0]\n",
    "print(\"Connect status:\",CON_STR[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7400e09-8b2c-47bb-bc5b-d434046e9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref1_pos = ()\n",
    "ref2_pos = ()\n",
    "Z_PLANE  = None\n",
    "\n",
    "def set_ref_1():\n",
    "    pos = dType.GetPose(api)\n",
    "    x = pos[0]\n",
    "    y = pos[1]\n",
    "    ref1_pos = (x,y)\n",
    "\n",
    "def set_ref_2():\n",
    "    pos = dType.GetPose(api)\n",
    "    x = pos[0]\n",
    "    y = pos[1]\n",
    "    ref2_pos = (x,y)\n",
    "\n",
    "def set_Z():\n",
    "    global Z_PLANE\n",
    "    pos = dType.GetPose(api)\n",
    "    Z_PLANE = pos[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db40de7d-d8e3-4dac-97e5-d592be12a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_image = cv2.imread('image2-edit.png')\n",
    "plt.imshow(main_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df83f83c-7835-4e43-8980-d035e9f4e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_image = cv2.cvtColor(main_image, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5033568-9d16-4dab-a4b8-24d9587343a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hsv_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00ba62-a0dd-4367-854a-5fc97dc06d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifyColor(image, coordinates, radius=5):\n",
    "\n",
    "    # Convert the image from BGR to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Get the coordinates\n",
    "    x, y = coordinates\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    # Extract the region of interest (ROI) around the coordinates\n",
    "    roi = hsv_image[y-radius:y+radius+1, x-radius:x+radius+1]\n",
    "\n",
    "    # Calculate the mean HSV value of the ROI\n",
    "    mean_hsv = np.mean(roi, axis=(0, 1))\n",
    "\n",
    "    # Define HSV ranges for red, green, and blue\n",
    "    red_lower1 = np.array([0, 70, 50])\n",
    "    red_upper1 = np.array([10, 255, 255])\n",
    "    red_lower2 = np.array([170, 70, 50])\n",
    "    red_upper2 = np.array([180, 255, 255])\n",
    "    green_lower = np.array([35, 50, 50])\n",
    "    green_upper = np.array([85, 255, 255])\n",
    "    blue_lower = np.array([100, 150, 0])\n",
    "    blue_upper = np.array([140, 255, 255])\n",
    "\n",
    "    # Check the color\n",
    "    if ((red_lower1 <= mean_hsv).all() and (mean_hsv <= red_upper1).all()) or \\\n",
    "       ((red_lower2 <= mean_hsv).all() and (mean_hsv <= red_upper2).all()):\n",
    "        color = \"red\"\n",
    "    elif (green_lower <= mean_hsv).all() and (mean_hsv <= green_upper).all():\n",
    "        color = \"green\"\n",
    "    elif (blue_lower <= mean_hsv).all() and (mean_hsv <= blue_upper).all():\n",
    "        color = \"blue\"\n",
    "    else:\n",
    "        color = \"unknown\"\n",
    "\n",
    "    return color\n",
    "\n",
    "checker = {}\n",
    "checker[\"red\"] = 'o'\n",
    "checker[\"green\"] = 'x'\n",
    "def readBoard(image):\n",
    "    board = np.array(4,4)\n",
    "    for x_pos in range(1,4):\n",
    "        for y_pos in range(1,4):\n",
    "            idx = (y_pos-1) * 3 + x_pos\n",
    "            pixel_pos = pos_cord[idx]\n",
    "            color = identifyColor(image, pixel_pos)\n",
    "            checker[color]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ddbbc3-b75d-4027-85fb-47519f4f3f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "identifyColor(main_image, pos_cord[1]) # pos_cord, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd01a0ea-4ade-4062-8809-65acabb7f30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e21b48-e4c1-4849-93d3-4a40c350c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Draw matches\n",
    "# img_matches = cv2.drawMatches(template_image, kp1, main_image, kp2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# # Show matches\n",
    "# plt.imshow(img_matches)\n",
    "# plt.show()\n",
    "\n",
    "# # Extract location of good matches\n",
    "# if len(good_matches) > 4:\n",
    "#     src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 2)\n",
    "#     dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 2)\n",
    "\n",
    "#     # Find homography\n",
    "#     M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "#     matches_mask = mask.ravel().tolist()\n",
    "\n",
    "#     # Get the corners from the template image\n",
    "#     h, w = template_image.shape\n",
    "#     pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "\n",
    "#     # Apply the perspective transformation to get the coordinates in the main image\n",
    "#     dst = cv2.perspectiveTransform(pts, M)\n",
    "\n",
    "#     # Draw the detected template in the main image\n",
    "#     main_image_with_template = cv2.polylines(main_image, [np.int32(dst)], True, 255, 3, cv2.LINE_AA)\n",
    "\n",
    "#     # Show the final image with the template location\n",
    "#     plt.imshow(main_image_with_template, cmap='gray')\n",
    "#     plt.show()\n",
    "\n",
    "#     # Print the coordinates\n",
    "#     for point in dst:\n",
    "#         print(f\"Template found at: {point[0]}\")\n",
    "# else:\n",
    "#     print(\"Not enough matches are found - {}/{}\".format(len(good_matches), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a092e7-92e9-4511-af5b-38298462bce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
